# SoundMood æŠ€æœ¯æ–‡æ¡£

## Part 4: AI æœåŠ¡é›†æˆ + å®Œæ•´éƒ¨ç½²æŒ‡å—

---

## ğŸ“‹ æ–‡æ¡£å¯¼èˆª

| éƒ¨åˆ† | å†…å®¹ | çŠ¶æ€ |
|------|------|------|
| Part 1 | é¡¹ç›®æ¶æ„ã€ç¯å¢ƒå‡†å¤‡ã€æ•°æ®åº“è®¾è®¡ | âœ… å·²å®Œæˆ |
| Part 2 | åç«¯ API å®Œæ•´ä»£ç  | âœ… å·²å®Œæˆ |
| Part 3 | Flutter å‰ç«¯å®Œæ•´ä»£ç  | âœ… å·²å®Œæˆ |
| **Part 4** | AI æœåŠ¡é›†æˆ + éƒ¨ç½²æŒ‡å— | ğŸ“– å½“å‰æ–‡æ¡£ |

---

## 1. AI æœåŠ¡å®ç°

### æ–‡ä»¶: `backend/app/services/ai_service.py`

```python
"""
AI éŸ³ä¹ç”ŸæˆæœåŠ¡
é›†æˆ Whisperã€Claudeã€MusicGen ç­‰AIæ¨¡å‹
"""
import os
import time
import json
import httpx
from pathlib import Path
from typing import Optional, Dict, Any
from sqlalchemy.orm import Session

from app.config import settings
from app.models.music import Music, GenerationLog, MusicStatus
from app.models.user import User

class AIService:
    """
    AI æœåŠ¡ç»Ÿä¸€æ¥å£
    """
    
    def __init__(self):
        self.openai_key = settings.OPENAI_API_KEY
        self.anthropic_key = settings.ANTHROPIC_API_KEY
        self.suno_key = settings.SUNO_API_KEY
        
    async def generate_music_from_text(
        self,
        db: Session,
        music_id: int,
        text: str,
        duration: int = 30
    ):
        """
        ä»æ–‡æœ¬ç”ŸæˆéŸ³ä¹çš„å®Œæ•´æµç¨‹
        """
        start_time = time.time()
        
        try:
            music = db.query(Music).filter(Music.id == music_id).first()
            if not music:
                return
            
            # 1. æƒ…æ„Ÿåˆ†æ
            print(f"[Music {music_id}] å¼€å§‹æƒ…æ„Ÿåˆ†æ...")
            analysis_start = time.time()
            emotion_analysis = await self._analyze_emotion_from_text(text)
            analysis_time = int((time.time() - analysis_start) * 1000)
            
            # 2. ç”ŸæˆéŸ³ä¹æç¤ºè¯
            music_prompt = self._build_music_prompt(emotion_analysis)
            
            # 3. è°ƒç”¨éŸ³ä¹ç”ŸæˆAPI
            print(f"[Music {music_id}] å¼€å§‹ç”ŸæˆéŸ³ä¹...")
            gen_start = time.time()
            music_url = await self._generate_music_with_suno(
                music_prompt,
                duration
            )
            gen_time = int((time.time() - gen_start) * 1000)
            
            # 4. æ›´æ–°æ•°æ®åº“
            music.music_url = music_url
            music.emotion_tags = emotion_analysis.get("tags", [])
            music.ai_analysis = emotion_analysis.get("description", "")
            music.status = MusicStatus.completed
            music.bpm = emotion_analysis.get("bpm", 120)
            music.genre = emotion_analysis.get("genre", "ambient")
            
            # 5. è®°å½•ç”Ÿæˆæ—¥å¿—
            total_time = int((time.time() - start_time) * 1000)
            log = GenerationLog(
                music_id=music_id,
                analysis_time=analysis_time,
                generation_time=gen_time,
                total_time=total_time,
                llm_model="claude-3-sonnet",
                music_model="suno-v3",
                raw_prompt=music_prompt,
                raw_response=json.dumps(emotion_analysis)
            )
            db.add(log)
            db.commit()
            
            print(f"[Music {music_id}] âœ… ç”Ÿæˆå®Œæˆ! æ€»è€—æ—¶: {total_time}ms")
            
        except Exception as e:
            print(f"[Music {music_id}] âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            music.status = MusicStatus.failed
            log = GenerationLog(
                music_id=music_id,
                error_message=str(e),
                total_time=int((time.time() - start_time) * 1000)
            )
            db.add(log)
            db.commit()
    
    async def generate_music_from_voice(
        self,
        db: Session,
        music_id: int,
        audio_path: str,
        duration: int = 30
    ):
        """
        ä»è¯­éŸ³ç”ŸæˆéŸ³ä¹
        """
        start_time = time.time()
        
        try:
            music = db.query(Music).filter(Music.id == music_id).first()
            if not music:
                return
            
            # 1. è¯­éŸ³è¯†åˆ«
            print(f"[Music {music_id}] å¼€å§‹è¯­éŸ³è¯†åˆ«...")
            asr_start = time.time()
            text = await self._transcribe_audio(audio_path)
            asr_time = int((time.time() - asr_start) * 1000)
            
            print(f"[Music {music_id}] è¯†åˆ«ç»“æœ: {text}")
            
            # 2. åç»­æµç¨‹ä¸æ–‡æœ¬ç”Ÿæˆç›¸åŒ
            analysis_start = time.time()
            emotion_analysis = await self._analyze_emotion_from_text(text)
            analysis_time = int((time.time() - analysis_start) * 1000)
            
            music_prompt = self._build_music_prompt(emotion_analysis)
            
            gen_start = time.time()
            music_url = await self._generate_music_with_suno(
                music_prompt,
                duration
            )
            gen_time = int((time.time() - gen_start) * 1000)
            
            # æ›´æ–°æ•°æ®åº“
            music.music_url = music_url
            music.emotion_tags = emotion_analysis.get("tags", [])
            music.ai_analysis = f"è¯­éŸ³è¯†åˆ«: {text}

{emotion_analysis.get('description', '')}"
            music.status = MusicStatus.completed
            music.bpm = emotion_analysis.get("bpm", 120)
            music.genre = emotion_analysis.get("genre", "ambient")
            
            total_time = int((time.time() - start_time) * 1000)
            log = GenerationLog(
                music_id=music_id,
                asr_time=asr_time,
                analysis_time=analysis_time,
                generation_time=gen_time,
                total_time=total_time,
                asr_model="whisper-base",
                llm_model="claude-3-sonnet",
                music_model="suno-v3",
                raw_prompt=music_prompt,
                raw_response=json.dumps(emotion_analysis)
            )
            db.add(log)
            db.commit()
            
            print(f"[Music {music_id}] âœ… ç”Ÿæˆå®Œæˆ!")
            
        except Exception as e:
            print(f"[Music {music_id}] âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            music.status = MusicStatus.failed
            log = GenerationLog(
                music_id=music_id,
                error_message=str(e)
            )
            db.add(log)
            db.commit()
    
    async def generate_music_from_image(
        self,
        db: Session,
        music_id: int,
        image_path: str,
        duration: int = 30
    ):
        """
        ä»å›¾ç‰‡ç”ŸæˆéŸ³ä¹
        """
        start_time = time.time()
        
        try:
            music = db.query(Music).filter(Music.id == music_id).first()
            if not music:
                return
            
            # 1. å›¾åƒç†è§£
            print(f"[Music {music_id}] å¼€å§‹åˆ†æå›¾ç‰‡...")
            analysis_start = time.time()
            emotion_analysis = await self._analyze_emotion_from_image(image_path)
            analysis_time = int((time.time() - analysis_start) * 1000)
            
            # 2. ç”ŸæˆéŸ³ä¹
            music_prompt = self._build_music_prompt(emotion_analysis)
            
            gen_start = time.time()
            music_url = await self._generate_music_with_suno(
                music_prompt,
                duration
            )
            gen_time = int((time.time() - gen_start) * 1000)
            
            # æ›´æ–°æ•°æ®åº“
            music.music_url = music_url
            music.emotion_tags = emotion_analysis.get("tags", [])
            music.ai_analysis = emotion_analysis.get("description", "")
            music.status = MusicStatus.completed
            music.bpm = emotion_analysis.get("bpm", 120)
            music.genre = emotion_analysis.get("genre", "ambient")
            
            total_time = int((time.time() - start_time) * 1000)
            log = GenerationLog(
                music_id=music_id,
                analysis_time=analysis_time,
                generation_time=gen_time,
                total_time=total_time,
                llm_model="claude-3-sonnet",
                music_model="suno-v3",
                raw_prompt=music_prompt,
                raw_response=json.dumps(emotion_analysis)
            )
            db.add(log)
            db.commit()
            
            print(f"[Music {music_id}] âœ… ç”Ÿæˆå®Œæˆ!")
            
        except Exception as e:
            print(f"[Music {music_id}] âŒ ç”Ÿæˆå¤±è´¥: {str(e)}")
            music.status = MusicStatus.failed
            db.commit()
    
    async def _transcribe_audio(self, audio_path: str) -> str:
        """
        ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«
        ä¸¤ç§æ–¹æ¡ˆ:
        1. æœ¬åœ° Whisper (éœ€è¦å®‰è£… openai-whisper)
        2. OpenAI API (åœ¨çº¿è°ƒç”¨,éœ€è¦API Key)
        """
        # æ–¹æ¡ˆ1: ä½¿ç”¨ OpenAI API (æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒ)
        if self.openai_key:
            async with httpx.AsyncClient() as client:
                with open(audio_path, "rb") as f:
                    response = await client.post(
                        "https://api.openai.com/v1/audio/transcriptions",
                        headers={
                            "Authorization": f"Bearer {self.openai_key}"
                        },
                        files={
                            "file": f
                        },
                        data={
                            "model": "whisper-1",
                            "language": "zh"
                        }
                    )
                result = response.json()
                return result.get("text", "")
        
        # æ–¹æ¡ˆ2: ä½¿ç”¨æœ¬åœ° Whisper (å¤‡é€‰æ–¹æ¡ˆ)
        else:
            try:
                import whisper
                model = whisper.load_model(settings.WHISPER_MODEL)
                result = model.transcribe(audio_path, language="zh")
                return result["text"]
            except ImportError:
                raise Exception("æœªå®‰è£… Whisper ä¸”æœªé…ç½® OpenAI API Key")
    
    async def _analyze_emotion_from_text(self, text: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Claude API è¿›è¡Œæƒ…æ„Ÿåˆ†æ
        """
        if not self.anthropic_key:
            # ç®€å•çš„è§„åˆ™åŒ¹é…ä½œä¸ºåå¤‡æ–¹æ¡ˆ
            return self._simple_emotion_analysis(text)
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿç‰¹å¾,å¹¶ä¸ºéŸ³ä¹ç”Ÿæˆæä¾›å‚æ•°å»ºè®®ã€‚

æ–‡æœ¬å†…å®¹:
{text}

è¯·ä»¥JSONæ ¼å¼è¿”å›,åŒ…å«ä»¥ä¸‹å­—æ®µ:
{{
    "tags": ["æƒ…æ„Ÿæ ‡ç­¾1", "æƒ…æ„Ÿæ ‡ç­¾2", "æƒ…æ„Ÿæ ‡ç­¾3"],
    "description": "è¯¦ç»†çš„æƒ…æ„Ÿæè¿°",
    "bpm": 120,  // å»ºè®®çš„èŠ‚å¥(60-180)
    "genre": "æµæ´¾",  // å¦‚: ambient, electronic, classical, popç­‰
    "mood": "æ•´ä½“æ°›å›´",
    "energy": "èƒ½é‡ç­‰çº§(1-10)"
}}
"""
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.anthropic.com/v1/messages",
                headers={
                    "x-api-key": self.anthropic_key,
                    "anthropic-version": "2023-06-01",
                    "content-type": "application/json"
                },
                json={
                    "model": "claude-3-sonnet-20240229",
                    "max_tokens": 1024,
                    "messages": [
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                },
                timeout=30.0
            )
            
            result = response.json()
            content = result["content"][0]["text"]
            
            # æå–JSON
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return self._simple_emotion_analysis(text)
    
    async def _analyze_emotion_from_image(self, image_path: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨ Claude Vision API è¿›è¡Œå›¾åƒæƒ…æ„Ÿåˆ†æ
        """
        if not self.anthropic_key:
            return self._simple_emotion_analysis("å›¾ç‰‡")
        
        # è¯»å–å¹¶ç¼–ç å›¾ç‰‡
        import base64
        with open(image_path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")
        
        # æ£€æµ‹å›¾ç‰‡æ ¼å¼
        ext = Path(image_path).suffix.lower()
        media_type = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".webp": "image/webp"
        }.get(ext, "image/jpeg")
        
        prompt = """è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„æƒ…æ„Ÿæ°›å›´,ä¸ºéŸ³ä¹ç”Ÿæˆæä¾›å‚æ•°å»ºè®®ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›:
{
    "tags": ["æƒ…æ„Ÿæ ‡ç­¾1", "æƒ…æ„Ÿæ ‡ç­¾2", "æƒ…æ„Ÿæ ‡ç­¾3"],
    "description": "å›¾ç‰‡çš„æƒ…æ„Ÿæè¿°",
    "bpm": 120,
    "genre": "æµæ´¾",
    "mood": "æ•´ä½“æ°›å›´",
    "energy": "èƒ½é‡ç­‰çº§(1-10)"
}"""
        
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.anthropic.com/v1/messages",
                headers={
                    "x-api-key": self.anthropic_key,
                    "anthropic-version": "2023-06-01",
                    "content-type": "application/json"
                },
                json={
                    "model": "claude-3-sonnet-20240229",
                    "max_tokens": 1024,
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": media_type,
                                        "data": image_data
                                    }
                                },
                                {
                                    "type": "text",
                                    "text": prompt
                                }
                            ]
                        }
                    ]
                },
                timeout=30.0
            )
            
            result = response.json()
            content = result["content"][0]["text"]
            
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return self._simple_emotion_analysis("å›¾ç‰‡")
    
    def _simple_emotion_analysis(self, text: str) -> Dict[str, Any]:
        """
        ç®€å•çš„æƒ…æ„Ÿåˆ†æåå¤‡æ–¹æ¡ˆ
        """
        # å…³é”®è¯åŒ¹é…
        happy_keywords = ["å¼€å¿ƒ", "å¿«ä¹", "å…´å¥‹", "æ„‰å¿«", "é˜³å…‰"]
        sad_keywords = ["ä¼¤å¿ƒ", "éš¾è¿‡", "å¤±è½", "å­¤ç‹¬", "æ€å¿µ"]
        calm_keywords = ["å¹³é™", "å®‰å®", "æ”¾æ¾", "èˆ’é€‚", "å®é™"]
        
        text_lower = text.lower()
        
        if any(kw in text_lower for kw in happy_keywords):
            return {
                "tags": ["å¿«ä¹", "æ´»åŠ›", "æ˜äº®"],
                "description": "å……æ»¡æ´»åŠ›çš„å¿«ä¹æ°›å›´",
                "bpm": 130,
                "genre": "pop",
                "mood": "uplifting",
                "energy": 8
            }
        elif any(kw in text_lower for kw in sad_keywords):
            return {
                "tags": ["å¿§éƒ", "æ·±æ²‰", "æ„Ÿæ€§"],
                "description": "æ·±æ²‰çš„å¿§éƒæƒ…æ„Ÿ",
                "bpm": 80,
                "genre": "ambient",
                "mood": "melancholic",
                "energy": 3
            }
        elif any(kw in text_lower for kw in calm_keywords):
            return {
                "tags": ["å¹³é™", "èˆ’ç¼“", "å†¥æƒ³"],
                "description": "å®é™èˆ’ç¼“çš„æ°›å›´",
                "bpm": 90,
                "genre": "ambient",
                "mood": "peaceful",
                "energy": 4
            }
        else:
            return {
                "tags": ["ä¸­æ€§", "æ°›å›´", "æµè¡Œ"],
                "description": "å¹³è¡¡çš„æƒ…æ„Ÿè¡¨è¾¾",
                "bpm": 110,
                "genre": "electronic",
                "mood": "neutral",
                "energy": 5
            }
    
    def _build_music_prompt(self, emotion_analysis: Dict[str, Any]) -> str:
        """
        æ ¹æ®æƒ…æ„Ÿåˆ†æç»“æœæ„å»ºéŸ³ä¹ç”Ÿæˆæç¤ºè¯
        """
        tags = ", ".join(emotion_analysis.get("tags", []))
        description = emotion_analysis.get("description", "")
        genre = emotion_analysis.get("genre", "ambient")
        bpm = emotion_analysis.get("bpm", 120)
        mood = emotion_analysis.get("mood", "")
        
        prompt = f"""Create an instrumental {genre} track with the following characteristics:

Mood: {mood}
Emotion: {description}
Tags: {tags}
BPM: {bpm}

The music should evoke {tags} feelings and maintain a {mood} atmosphere throughout."""
        
        return prompt
    
    async def _generate_music_with_suno(
        self,
        prompt: str,
        duration: int = 30
    ) -> str:
        """
        ä½¿ç”¨ Suno API ç”ŸæˆéŸ³ä¹
        
        æ³¨æ„: Suno æ˜¯å•†ä¸šAPI,éœ€è¦è´­ä¹°è®¢é˜…
        è¿™é‡Œæä¾›æ¥å£ç¤ºä¾‹,å®é™…ä½¿ç”¨æ—¶éœ€è¦:
        1. æ³¨å†Œ Suno è´¦å·
        2. è·å– API Key
        3. æ ¹æ®å®˜æ–¹æ–‡æ¡£è°ƒç”¨
        
        æ›¿ä»£æ–¹æ¡ˆ:
        - Mubert API (https://mubert.com/)
        - Soundful API
        - æœ¬åœ° MusicGen æ¨¡å‹
        """
        if not self.suno_key:
            # è¿”å›ç¤ºä¾‹éŸ³ä¹æ–‡ä»¶(å¼€å‘é˜¶æ®µ)
            print("âš ï¸ æœªé…ç½® Suno API,è¿”å›ç¤ºä¾‹éŸ³ä¹")
            return "/uploads/music/sample.mp3"
        
        # Suno API è°ƒç”¨ç¤ºä¾‹
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.suno.ai/v1/generate",
                headers={
                    "Authorization": f"Bearer {self.suno_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "prompt": prompt,
                    "duration": duration,
                    "style": "instrumental"
                },
                timeout=120.0
            )
            
            result = response.json()
            audio_url = result.get("audio_url", "")
            
            # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°æœ¬åœ°
            if audio_url:
                import uuid
                filename = f"{uuid.uuid4()}.mp3"
                local_path = settings.MUSIC_DIR / filename
                
                audio_response = await client.get(audio_url)
                with open(local_path, "wb") as f:
                    f.write(audio_response.content)
                
                return f"/uploads/music/{filename}"
            
            return "/uploads/music/sample.mp3"
```

---

## 2. æœ¬åœ°æµ‹è¯•æ–¹æ¡ˆ

å¦‚æœä½ æš‚æ—¶æ²¡æœ‰ AI API Key,å¯ä»¥ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•ã€‚

### åˆ›å»ºç¤ºä¾‹éŸ³ä¹æ–‡ä»¶

```bash
# åœ¨ backend/uploads/music ç›®å½•ä¸‹
mkdir -p backend/uploads/music

# ä¸‹è½½ä¸€ä¸ªç¤ºä¾‹ MP3 æˆ–åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶ç”¨äºæµ‹è¯•
touch backend/uploads/music/sample.mp3
```

### ä¿®æ”¹ AI Service ä½¿ç”¨æµ‹è¯•æ¨¡å¼

åœ¨ `backend/app/config.py` ä¸­æ·»åŠ :

```python
# AI æµ‹è¯•æ¨¡å¼
USE_MOCK_AI: bool = os.getenv("USE_MOCK_AI", "True").lower() == "true"
```

---

## 3. å®Œæ•´éƒ¨ç½²æŒ‡å—

### 3.1 å¼€å‘ç¯å¢ƒéƒ¨ç½²

#### æ­¥éª¤ 1: å¯åŠ¨åç«¯

```bash
cd soundmood/backend

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate  # Mac/Linux
# æˆ–
venv\Scripts\activate  # Windows

# å¯åŠ¨æœåŠ¡
python run.py
```

åç«¯å°†è¿è¡Œåœ¨ http://localhost:8000

#### æ­¥éª¤ 2: å¯åŠ¨ Flutter

æ–°å¼€ä¸€ä¸ªç»ˆç«¯:

```bash
cd soundmood/frontend

# åˆ—å‡ºå¯ç”¨è®¾å¤‡
flutter devices

# è¿è¡Œåº”ç”¨ (é€‰æ‹©ä½ çš„è®¾å¤‡)
flutter run
```

### 3.2 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### åç«¯éƒ¨ç½² (Linux æœåŠ¡å™¨)

##### 1. æœåŠ¡å™¨å‡†å¤‡

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…å¿…è¦è½¯ä»¶
sudo apt install python3.10 python3.10-venv nginx mysql-server -y
```

##### 2. é…ç½® MySQL

```bash
sudo mysql_secure_installation

# åˆ›å»ºæ•°æ®åº“å’Œç”¨æˆ·
sudo mysql -u root -p

CREATE DATABASE soundmood CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
CREATE USER 'soundmood'@'localhost' IDENTIFIED BY 'your_secure_password';
GRANT ALL PRIVILEGES ON soundmood.* TO 'soundmood'@'localhost';
FLUSH PRIVILEGES;
EXIT;
```

##### 3. éƒ¨ç½²åç«¯ä»£ç 

```bash
# åˆ›å»ºéƒ¨ç½²ç›®å½•
sudo mkdir -p /var/www/soundmood
sudo chown $USER:$USER /var/www/soundmood

# ä¸Šä¼ ä»£ç  (ä½¿ç”¨ git æˆ– scp)
cd /var/www/soundmood
git clone <your-repo-url> .

# æˆ–ä½¿ç”¨ scp
# scp -r backend/ user@server:/var/www/soundmood/

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
cd backend
python3.10 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

##### 4. é…ç½®ç¯å¢ƒå˜é‡

```bash
# åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®
nano .env
```

å¡«å…¥:

```bash
DEBUG=False
HOST=0.0.0.0
PORT=8000

DB_HOST=localhost
DB_PORT=3306
DB_USER=soundmood
DB_PASSWORD=your_secure_password
DB_NAME=soundmood

SECRET_KEY=<ç”Ÿæˆä¸€ä¸ªå¼ºéšæœºå¯†é’¥>

# AI API Keys (å¦‚æœæœ‰)
OPENAI_API_KEY=sk-xxx
ANTHROPIC_API_KEY=sk-ant-xxx
SUNO_API_KEY=xxx
```

ç”Ÿæˆå®‰å…¨çš„ SECRET_KEY:

```bash
python -c "import secrets; print(secrets.token_urlsafe(32))"
```

##### 5. ä½¿ç”¨ Gunicorn + Systemd

å®‰è£… Gunicorn:

```bash
pip install gunicorn
```

åˆ›å»º systemd æœåŠ¡:

```bash
sudo nano /etc/systemd/system/soundmood.service
```

å†…å®¹:

```ini
[Unit]
Description=SoundMood API Service
After=network.target

[Service]
Type=notify
User=www-data
Group=www-data
WorkingDirectory=/var/www/soundmood/backend
Environment="PATH=/var/www/soundmood/backend/venv/bin"
ExecStart=/var/www/soundmood/backend/venv/bin/gunicorn \
    -c gunicorn_config.py \
    app.main:app

[Install]
WantedBy=multi-user.target
```

åˆ›å»º Gunicorn é…ç½®:

```bash
nano /var/www/soundmood/backend/gunicorn_config.py
```

å†…å®¹:

```python
bind = "127.0.0.1:8000"
workers = 4
worker_class = "uvicorn.workers.UvicornWorker"
accesslog = "/var/log/soundmood/access.log"
errorlog = "/var/log/soundmood/error.log"
```

åˆ›å»ºæ—¥å¿—ç›®å½•:

```bash
sudo mkdir -p /var/log/soundmood
sudo chown www-data:www-data /var/log/soundmood
```

å¯åŠ¨æœåŠ¡:

```bash
sudo systemctl daemon-reload
sudo systemctl start soundmood
sudo systemctl enable soundmood
sudo systemctl status soundmood
```

##### 6. é…ç½® Nginx

```bash
sudo nano /etc/nginx/sites-available/soundmood
```

å†…å®¹:

```nginx
server {
    listen 80;
    server_name your-domain.com;

    client_max_body_size 100M;

    # API
    location /api {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # é™æ€æ–‡ä»¶
    location /uploads {
        alias /var/www/soundmood/backend/uploads;
        expires 30d;
        add_header Cache-Control "public, immutable";
    }

    # API æ–‡æ¡£
    location /docs {
        proxy_pass http://127.0.0.1:8000;
    }
}
```

å¯ç”¨ç«™ç‚¹:

```bash
sudo ln -s /etc/nginx/sites-available/soundmood /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx
```

##### 7. é…ç½® HTTPS (Let's Encrypt)

```bash
sudo apt install certbot python3-certbot-nginx -y
sudo certbot --nginx -d your-domain.com
```

#### å‰ç«¯éƒ¨ç½²

##### Android APK æ‰“åŒ…

```bash
cd soundmood/frontend

# æ„å»º APK
flutter build apk --release

# ç”Ÿæˆçš„æ–‡ä»¶åœ¨:
# build/app/outputs/flutter-apk/app-release.apk
```

##### iOS æ‰“åŒ… (éœ€è¦ Mac + Xcode)

```bash
flutter build ios --release
```

ç„¶ååœ¨ Xcode ä¸­æ‰“å¼€é¡¹ç›®è¿›è¡Œç­¾åå’Œå‘å¸ƒã€‚

---

## 4. API å¯†é’¥è·å–æŒ‡å—

### 4.1 OpenAI (Whisper)

1. è®¿é—® https://platform.openai.com/
2. æ³¨å†Œè´¦å·å¹¶ç™»å½•
3. ç‚¹å‡»å³ä¸Šè§’å¤´åƒ â†’ "View API keys"
4. ç‚¹å‡» "Create new secret key"
5. å¤åˆ¶å¹¶ä¿å­˜å¯†é’¥ (åªæ˜¾ç¤ºä¸€æ¬¡)

### 4.2 Anthropic (Claude)

1. è®¿é—® https://console.anthropic.com/
2. æ³¨å†Œè´¦å·å¹¶ç™»å½•
3. è¿›å…¥ "API Keys" é¡µé¢
4. ç‚¹å‡» "Create Key"
5. å¤åˆ¶å¹¶ä¿å­˜å¯†é’¥

### 4.3 Suno (éŸ³ä¹ç”Ÿæˆ)

Suno ç›®å‰ä¸»è¦é€šè¿‡ç½‘é¡µç‰ˆä½¿ç”¨,APIè®¿é—®éœ€è¦è”ç³»å®˜æ–¹:

1. è®¿é—® https://suno.com/
2. ä½¿ç”¨ç½‘é¡µç‰ˆè¿›è¡Œæµ‹è¯•
3. å¦‚éœ€ API è®¿é—®,è”ç³» support@suno.com

**æ›¿ä»£æ–¹æ¡ˆ**:

- **Mubert**: https://mubert.com/render (æä¾›API)
- **Soundful**: https://soundful.com/ (AIéŸ³ä¹ç”Ÿæˆ)
- **æœ¬åœ°æ–¹æ¡ˆ**: ä½¿ç”¨ Meta çš„ MusicGen æ¨¡å‹

---

## 5. å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: åç«¯å¯åŠ¨å¤±è´¥

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
lsof -i :8000

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
mysql -u soundmood -p soundmood

# æŸ¥çœ‹æ—¥å¿—
cat /var/log/soundmood/error.log
```

### Q2: Flutter è¿æ¥ä¸ä¸Šåç«¯

æ£€æŸ¥ `lib/config/app_config.dart` ä¸­çš„ `baseUrl`:

- çœŸæœºæµ‹è¯•: ä½¿ç”¨ç”µè„‘çš„å±€åŸŸç½‘ IP (å¦‚ `http://192.168.1.100:8000`)
- æ¨¡æ‹Ÿå™¨: 
  - Android: `http://10.0.2.2:8000`
  - iOS: `http://localhost:8000`

### Q3: AI ç”Ÿæˆå¤±è´¥

1. æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. æŸ¥çœ‹åç«¯æ—¥å¿—ä¸­çš„å…·ä½“é”™è¯¯
4. ç¡®è®¤ API ä½™é¢å……è¶³

---

## 6. æ€§èƒ½ä¼˜åŒ–å»ºè®®

### åç«¯ä¼˜åŒ–

1. **ä½¿ç”¨ Redis ç¼“å­˜**:
```python
# ç¼“å­˜æƒ…æ„Ÿåˆ†æç»“æœ
# ç›¸åŒæ–‡æœ¬ä¸éœ€è¦é‡å¤åˆ†æ
```

2. **å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—**:
```python
# ä½¿ç”¨ Celery å¤„ç†è€—æ—¶çš„ AI ç”Ÿæˆ
# pip install celery redis
```

3. **CDN åŠ é€Ÿ**:
```python
# å°†ç”Ÿæˆçš„éŸ³ä¹æ–‡ä»¶ä¸Šä¼ åˆ°äº‘å­˜å‚¨
# å¦‚ AWS S3, é˜¿é‡Œäº‘ OSS
```

### å‰ç«¯ä¼˜åŒ–

1. **éŸ³é¢‘é¢„åŠ è½½**:
```dart
// æå‰ç¼“å­˜å³å°†æ’­æ”¾çš„éŸ³ä¹
```

2. **å›¾ç‰‡å‹ç¼©**:
```dart
// ä¸Šä¼ å‰å‹ç¼©å›¾ç‰‡
import 'package:image/image.dart' as img;
```

3. **ç¦»çº¿ç¼“å­˜**:
```dart
// ä½¿ç”¨ sqflite ç¼“å­˜éŸ³ä¹åˆ—è¡¨
```

---

## 7. åŠŸèƒ½æ‰©å±•å»ºè®®

### 7.1 ç¤¾äº¤åŠŸèƒ½

- åˆ†äº«éŸ³ä¹åˆ°ç¤¾äº¤åª’ä½“
- éŸ³ä¹ç¤¾åŒº/å¹¿åœº
- ç”¨æˆ·å…³æ³¨ç³»ç»Ÿ

### 7.2 é«˜çº§åŠŸèƒ½

- éŸ³ä¹æ··éŸ³ç¼–è¾‘
- å¤šè½¨é“å åŠ 
- å®æ—¶åä½œåˆ›ä½œ
- éŸ³ä¹é£æ ¼è¿ç§»

### 7.3 å•†ä¸šåŒ–

- ä¼šå‘˜è®¢é˜… (æ›´é•¿çš„ç”Ÿæˆæ—¶é•¿)
- éŸ³ä¹ä¸‹è½½
- ç‰ˆæƒæˆæƒ
- ä¼ä¸šå®šåˆ¶

---

## 8. é¡¹ç›®æ¸…å•

å®Œæˆä»¥ä¸‹æ£€æŸ¥æ¸…å•ç¡®ä¿é¡¹ç›®å¯ä»¥è¿è¡Œ:

### åç«¯æ¸…å•

- [ ] MySQL æ•°æ®åº“å·²åˆ›å»º
- [ ] Python è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»º
- [ ] ä¾èµ–å·²å®‰è£… (`pip install -r requirements.txt`)
- [ ] `.env` æ–‡ä»¶å·²é…ç½®
- [ ] æ•°æ®åº“è¡¨å·²åˆ›å»º (è‡ªåŠ¨è¿è¡Œ)
- [ ] åç«¯å¯ä»¥å¯åŠ¨ (`python run.py`)
- [ ] API æ–‡æ¡£å¯è®¿é—® (http://localhost:8000/api/docs)

### å‰ç«¯æ¸…å•

- [ ] Flutter SDK å·²å®‰è£…
- [ ] Android Studio å·²é…ç½®
- [ ] ä¾èµ–å·²å®‰è£… (`flutter pub get`)
- [ ] API åœ°å€å·²é…ç½®æ­£ç¡®
- [ ] å¯ä»¥è¿è¡Œ (`flutter run`)

### AI æœåŠ¡æ¸…å•

- [ ] å·²è·å– AI API å¯†é’¥ (æˆ–ä½¿ç”¨æµ‹è¯•æ¨¡å¼)
- [ ] API å¯†é’¥å·²å¡«å…¥ `.env`
- [ ] å·²æµ‹è¯•éŸ³ä¹ç”ŸæˆåŠŸèƒ½

---

## 9. æ€»ç»“

æ­å–œ!ğŸ‰ ä½ å·²ç»å®Œæˆäº† SoundMood é¡¹ç›®çš„å®Œæ•´æŠ€æœ¯æ–‡æ¡£å­¦ä¹ ã€‚

è¿™ä¸ªé¡¹ç›®åŒ…å«:
- âœ… ç°ä»£åŒ–çš„åç«¯ API (FastAPI)
- âœ… ç²¾ç¾çš„ç§»åŠ¨ç«¯ç•Œé¢ (Flutter)
- âœ… å®Œæ•´çš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ
- âœ… AI é©±åŠ¨çš„éŸ³ä¹ç”Ÿæˆ
- âœ… ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ–¹æ¡ˆ

æ¥ä¸‹æ¥ä½ å¯ä»¥:
1. æŒ‰ç…§æ–‡æ¡£ä¸€æ­¥æ­¥å®ç°é¡¹ç›®
2. æ ¹æ®éœ€æ±‚å®šåˆ¶å’Œæ‰©å±•åŠŸèƒ½
3. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒä¾›ç”¨æˆ·ä½¿ç”¨

å¦‚æœ‰é—®é¢˜,å¯ä»¥å‚è€ƒæ–‡æ¡£ä¸­çš„å¸¸è§é—®é¢˜éƒ¨åˆ†,æˆ–æŸ¥é˜…å®˜æ–¹æ–‡æ¡£:
- FastAPI: https://fastapi.tiangolo.com/
- Flutter: https://flutter.dev/docs
- Claude API: https://docs.anthropic.com/

ç¥ä½ å¼€å‘æ„‰å¿«!ğŸš€

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æ›´æ–°æ—¥æœŸ**: 2025å¹´1æœˆ  
**ä½œè€…**: AI Assistant  
**è”ç³»æ–¹å¼**: (å¡«å…¥ä½ çš„è”ç³»æ–¹å¼)
